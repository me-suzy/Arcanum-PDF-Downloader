#!/usr/bin/env python3
"""
Script mic pentru verificarea ordinii cronologice Ã®n state.json
"""

import json
import os
from datetime import datetime

def check_json_structure():
    """VerificÄƒ cum sunt salvate issue-urile Ã®n state.json"""
    
    state_file = "D:\\state.json"
    
    if not os.path.exists(state_file):
        print(f"âŒ Nu gÄƒsesc {state_file}")
        return
    
    print("ğŸ” ANALIZA state.json")
    print("=" * 60)
    
    try:
        with open(state_file, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        issues = data.get("downloaded_issues", [])
        
        print(f"ğŸ“Š Total issues gÄƒsite: {len(issues)}")
        print(f"ğŸ“Š Count Ã®n JSON: {data.get('count', 0)}")
        print(f"ğŸ“Š Pages downloaded: {data.get('pages_downloaded', 0)}")
        
        # SeparÄƒ issue-urile parÈ›iale È™i complete
        partial_issues = []
        complete_issues = []
        
        for issue in issues:
            completed_at = issue.get("completed_at", "")
            if completed_at:
                complete_issues.append(issue)
            else:
                partial_issues.append(issue)
        
        print(f"\nğŸ“‹ STRUCTURA:")
        print(f"   ğŸ”„ Issue-uri parÈ›iale: {len(partial_issues)}")
        print(f"   âœ… Issue-uri complete: {len(complete_issues)}")
        
        # VerificÄƒ issue-urile parÈ›iale
        if partial_issues:
            print(f"\nğŸ”„ ISSUE-URI PARÈšIALE:")
            for i, issue in enumerate(partial_issues[:5]):  # Primele 5
                url = issue.get("url", "").split("/")[-1]
                progress = issue.get("last_successful_segment_end", 0)
                total = issue.get("total_pages", 0)
                print(f"   {i+1}. {url} - progres: {progress}/{total}")
        
        # VerificÄƒ ordinea cronologicÄƒ a celor complete
        if complete_issues:
            print(f"\nâœ… ISSUE-URI COMPLETE (ordinea din JSON):")
            
            # AfiÈ™eazÄƒ primele 10 pentru verificare
            for i, issue in enumerate(complete_issues[:10]):
                url = issue.get("url", "").split("/")[-1]
                completed_at = issue.get("completed_at", "N/A")
                pages = issue.get("pages", 0)
                
                # FormateazÄƒ data pentru citire mai uÈ™oarÄƒ
                try:
                    dt = datetime.fromisoformat(completed_at.replace('Z', '+00:00'))
                    formatted_date = dt.strftime("%Y-%m-%d %H:%M")
                except:
                    formatted_date = completed_at
                
                print(f"   {i+1}. {url}")
                print(f"      ğŸ“… Completat: {formatted_date}")
                print(f"      ğŸ“„ Pagini: {pages}")
        
        # VerificÄƒ dacÄƒ sunt sortate cronologic corect
        print(f"\nğŸ• VERIFICARE SORTARE CRONOLOGICÄ‚:")
        
        if len(complete_issues) >= 2:
            is_sorted_correctly = True
            previous_datetime = None
            
            for i, issue in enumerate(complete_issues):
                completed_at = issue.get("completed_at", "")
                try:
                    current_datetime = datetime.fromisoformat(completed_at.replace('Z', '+00:00'))
                    
                    if previous_datetime and current_datetime > previous_datetime:
                        is_sorted_correctly = False
                        url = issue.get("url", "").split("/")[-1]
                        print(f"   âŒ EROARE la poziÈ›ia {i+1}: {url}")
                        print(f"      Este mai recent ({current_datetime}) decÃ¢t precedentul ({previous_datetime})")
                    
                    previous_datetime = current_datetime
                except Exception as e:
                    print(f"   âš  Nu pot parsa data pentru issue-ul {i+1}: {completed_at}")
            
            if is_sorted_correctly:
                print("   âœ… Issue-urile complete sunt sortate CORECT cronologic (cel mai recent primul)")
                
                # AfiÈ™eazÄƒ prima È™i ultima datÄƒ pentru confirmare
                try:
                    first_date = datetime.fromisoformat(complete_issues[0].get("completed_at", "").replace('Z', '+00:00'))
                    last_date = datetime.fromisoformat(complete_issues[-1].get("completed_at", "").replace('Z', '+00:00'))
                    
                    print(f"   ğŸ“… Cel mai recent: {first_date.strftime('%Y-%m-%d %H:%M')}")
                    print(f"   ğŸ“… Cel mai vechi: {last_date.strftime('%Y-%m-%d %H:%M')}")
                except:
                    pass
            else:
                print("   âŒ Issue-urile complete NU sunt sortate corect cronologic!")
        
        # VerificÄƒ recent_links
        recent_links = data.get("recent_links", [])
        if recent_links:
            print(f"\nğŸ”— RECENT LINKS (primele 5):")
            for i, link in enumerate(recent_links[:5]):
                url = link.get("url", "").split("/")[-1]
                timestamp = link.get("timestamp", "N/A")
                pages = link.get("pages", 0)
                
                try:
                    dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                    formatted_date = dt.strftime("%Y-%m-%d %H:%M")
                except:
                    formatted_date = timestamp
                    
                print(f"   {i+1}. {url} - {formatted_date} ({pages} pagini)")
        
        print(f"\nğŸ¯ REZUMAT:")
        total_complete = len([i for i in issues if i.get("completed_at")])
        total_partial = len([i for i in issues if not i.get("completed_at") and i.get("last_successful_segment_end", 0) > 0])
        
        print(f"   ğŸ“Š Total issues: {len(issues)}")
        print(f"   âœ… Complete: {total_complete}")
        print(f"   ğŸ”„ ParÈ›iale: {total_partial}")
        print(f"   ğŸ“„ Total pagini descÄƒrcate: {data.get('pages_downloaded', 0)}")
        
    except Exception as e:
        print(f"âŒ Eroare la citirea JSON: {e}")

def check_skip_urls():
    """VerificÄƒ È™i skip_urls.json"""
    
    skip_file = "D:\\skip_urls.json"
    
    if not os.path.exists(skip_file):
        print(f"\nğŸ“‹ Nu gÄƒsesc {skip_file}")
        return
    
    print(f"\nğŸ“‹ ANALIZA skip_urls.json")
    print("=" * 40)
    
    try:
        with open(skip_file, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        completed_urls = data.get("completed_urls", [])
        completed_collections = data.get("completed_collections", [])
        last_updated = data.get("last_updated", "N/A")
        
        print(f"ğŸ“Š URLs complete: {len(completed_urls)}")
        print(f"ğŸ“Š ColecÈ›ii complete: {len(completed_collections)}")
        print(f"ğŸ“Š Ultima actualizare: {last_updated}")
        
        if completed_urls:
            print(f"\nğŸ”— URLS COMPLETE (primele 5):")
            for i, url in enumerate(completed_urls[:5]):
                issue_name = url.split("/")[-1]
                print(f"   {i+1}. {issue_name}")
        
        if completed_collections:
            print(f"\nğŸ“š COLECÈšII COMPLETE:")
            for i, collection in enumerate(completed_collections):
                collection_name = collection.split("/")[-1]
                print(f"   {i+1}. {collection_name}")
                
    except Exception as e:
        print(f"âŒ Eroare la citirea skip_urls.json: {e}")

if __name__ == "__main__":
    print("ğŸ” VERIFICATOR JSON - ORDINEA CRONOLOGICÄ‚")
    print("=" * 70)
    
    check_json_structure()
    check_skip_urls()
    
    print("\n" + "=" * 70)
    print("âœ… VERIFICARE COMPLETÄ‚")