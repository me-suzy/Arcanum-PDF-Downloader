#!/usr/bin/env python3
"""
Automatizare descƒÉrcare PDF-uri din Arcanum (Gazeta Matematica):
- Conectare la sesiune Chrome existentƒÉ cu remote debugging.
- Dintr-o colec»õie extrage toate issue-urile (/en/view/...).
- Sare peste cele deja descƒÉrcate/completate.
- LimiteazƒÉ la 102 issue-uri pe zi.
- DetecteazƒÉ mesajul de limitƒÉ zilnicƒÉ »ôi opre»ôte progresul.
- Reia par»õial un issue neterminat (folosind last_successful_segment_end).
- PƒÉstreazƒÉ stare √Æn state.json inclusiv recent_links.
- La final, dacƒÉ totul e terminat, tipƒÉre»ôte mesajul final.
"""

import time
import os
import sys
import re
import json
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import WebDriverException, ElementClickInterceptedException

SKIP_URLS = {
    "https://adt.arcanum.com/en/view/GazetaMatematica_1922-23",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1923-24",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1924-25",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1925-26",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1926-27",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1929-30",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1930-31",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1931-32",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1932-33",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1933-34",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1934-35",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1934-35_Sup",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1935-36",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1935-36_Sup",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1936-37",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1936-37_Sup",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1937-38",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1937-38_Sup",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1938-39",
    "https://adt.arcanum.com/en/view/GazetaMatematica_1938-39_Sup"
}
DAILY_LIMIT = 102
STATE_FILENAME = "state.json"

class ChromePDFDownloader:
    def __init__(self, test_url, download_dir=None, batch_size=50, timeout=15):
        self.test_url = test_url
        self.batch_size = batch_size
        self.timeout = timeout
        self.download_dir = download_dir or os.getcwd()
        self.driver = None
        self.wait = None
        self.attached_existing = False
        self.state_path = os.path.join(self.download_dir, STATE_FILENAME)
        self.current_issue_url = None
        self._load_state()

    def _normalize_downloaded_issues(self, raw):
        normalized = []
        for item in raw:
            if isinstance(item, str):
                normalized.append({
                    "url": item.rstrip('/'),
                    "title": "",
                    "subtitle": "",
                    "pages": 0,
                    "completed_at": "",
                    "last_successful_segment_end": 0,
                    "total_pages": 0
                })
            elif isinstance(item, dict):
                normalized.append({
                    "url": item.get("url", "").rstrip('/'),
                    "title": item.get("title", ""),
                    "subtitle": item.get("subtitle", ""),
                    "pages": item.get("pages", 0),
                    "completed_at": item.get("completed_at", ""),
                    "last_successful_segment_end": item.get("last_successful_segment_end", 0),
                    "total_pages": item.get("total_pages", 0)
                })
        return normalized

    def _load_state(self):
        today = datetime.now().strftime("%Y-%m-%d")
        default = {
            "date": today,
            "count": 0,
            "downloaded_issues": [],
            "pages_downloaded": 0,
            "recent_links": []
        }
        self.state = default
        if os.path.exists(self.state_path):
            try:
                with open(self.state_path, "r", encoding="utf-8") as f:
                    loaded = json.load(f)
                if loaded.get("date") == today:
                    issues_raw = loaded.get("downloaded_issues", [])
                    issues = self._normalize_downloaded_issues(issues_raw)
                    self.state = {
                        "date": loaded.get("date", today),
                        "count": len(issues),
                        "downloaded_issues": issues,
                        "pages_downloaded": loaded.get("pages_downloaded", 0),
                        "recent_links": loaded.get("recent_links", []),
                    }
                else:
                    self.state = default
            except Exception as e:
                print(f"‚ö† Eroare la citirea stƒÉrii ({e}), resetez.")
                self.state = default
        self._save_state()

    def _save_state(self):
        try:
            with open(self.state_path, "w", encoding="utf-8") as f:
                json.dump(self.state, f, indent=2)
        except Exception as e:
            print(f"‚ö† Nu am putut salva state-ul: {e}")

    def remaining_quota(self):
        return max(0, DAILY_LIMIT - self.state.get("count", 0))

    def _update_partial_progress(self, issue_url, last_successful_segment_end):
        normalized = issue_url.rstrip('/')
        for item in self.state.setdefault("downloaded_issues", []):
            if item["url"] == normalized:
                item["last_successful_segment_end"] = last_successful_segment_end
                break
        else:
            self.state["downloaded_issues"].append({
                "url": normalized,
                "title": "",
                "subtitle": "",
                "pages": 0,
                "completed_at": "",
                "last_successful_segment_end": last_successful_segment_end,
                "total_pages": 0
            })
        self._save_state()

    def mark_issue_done(self, issue_url, pages_count, title=None, subtitle=None, total_pages=None):
        normalized = issue_url.rstrip('/')
        now_iso = datetime.now().isoformat(timespec="seconds")
        existing = None
        for item in self.state.setdefault("downloaded_issues", []):
            if item.get("url") == normalized:
                existing = item
                break

        record = {
            "url": normalized,
            "title": title or (existing.get("title") if existing else ""),
            "subtitle": subtitle or (existing.get("subtitle") if existing else ""),
            "pages": pages_count,
            "completed_at": now_iso,
            "last_successful_segment_end": pages_count,
            "total_pages": total_pages if total_pages is not None else (existing.get("total_pages") if existing else pages_count)
        }

        if existing:
            existing.update(record)
        else:
            self.state["downloaded_issues"].append(record)

        self.state["count"] = len(self.state.get("downloaded_issues", []))
        self.state["pages_downloaded"] = self.state.get("pages_downloaded", 0) + pages_count

        recent_entry = {
            "url": normalized,
            "title": record["title"],
            "subtitle": record["subtitle"],
            "pages": pages_count,
            "timestamp": now_iso
        }
        self.state.setdefault("recent_links", []).append(recent_entry)
        self._save_state()

    def setup_chrome_driver(self):
        try:
            print("üîß Ini»õializare WebDriver ‚Äì √Æncerc conectare la Chrome existent via remote debugging...")
            chrome_options = Options()
            chrome_options.add_experimental_option("debuggerAddress", "127.0.0.1:9222")
            prefs = {
                "download.default_directory": os.path.abspath(self.download_dir),
                "download.prompt_for_download": False,
                "download.directory_upgrade": True,
                "safebrowsing.enabled": True,
            }
            chrome_options.add_experimental_option("prefs", prefs)
            try:
                self.driver = webdriver.Chrome(options=chrome_options)
                self.wait = WebDriverWait(self.driver, self.timeout)
                self.attached_existing = True
                print("‚úÖ Conectat la instan»õa Chrome existentƒÉ cu succes.")
                return True
            except WebDriverException as e:
                print(f"‚ö† Conexiune la Chrome existent e»ôuat ({e}); pornesc o instan»õƒÉ nouƒÉ.")
                chrome_options = Options()
                chrome_options.add_experimental_option("prefs", prefs)
                chrome_options.add_argument("--no-sandbox")
                chrome_options.add_argument("--disable-dev-shm-usage")
                chrome_options.add_argument("--disable-gpu")
                chrome_options.add_argument("--window-size=1920,1080")
                chrome_options.add_argument("--incognito")
                self.driver = webdriver.Chrome(options=chrome_options)
                self.wait = WebDriverWait(self.driver, self.timeout)
                self.attached_existing = False
                print("‚úÖ Chrome nou pornit cu succes.")
                return True
        except WebDriverException as e:
            print(f"‚ùå Eroare la ini»õializarea WebDriver-ului: {e}")
            return False

    def navigate_to_page(self, url):
        try:
            print(f"üåê Navighez cƒÉtre: {url}")
            self.driver.get(url)
            self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'body')))
            print("‚úÖ Pagina √ÆncƒÉrcatƒÉ.")
            return True
        except Exception as e:
            print(f"‚ùå Eroare la navigare sau √ÆncƒÉrcare: {e}")
            return False

    def get_issue_metadata(self):
        title = ""
        subtitle = ""
        try:
            breadcrumb = self.driver.find_element(By.CSS_SELECTOR, "li.breadcrumb-item.active")
            try:
                sub_elem = breadcrumb.find_element(By.CSS_SELECTOR, "#pdfview-pdfcontents span")
                subtitle = sub_elem.text.strip()
            except Exception:
                subtitle = ""
            raw = breadcrumb.text.strip()
            if subtitle and subtitle in raw:
                title = raw.replace(subtitle, "").strip()
            else:
                title = raw
        except Exception:
            pass
        return title, subtitle

    def get_total_pages(self, max_attempts=5, delay_between=1.0):
        for attempt in range(1, max_attempts + 1):
            try:
                elems = self.driver.find_elements(By.CSS_SELECTOR, 'div.MuiInputAdornment-root.MuiInputAdornment-positionEnd')
                for el in elems:
                    text = el.text.strip()
                    match = re.search(r'/\s*(\d+)', text)
                    if match:
                        total = int(match.group(1))
                        print(f"‚úÖ (metoda principalƒÉ) NumƒÉrul total de pagini detectat: {total}")
                        return total
                all_texts = self.driver.find_elements(By.XPATH, "//*[contains(text(), '/')]")
                for el in all_texts:
                    text = el.text.strip()
                    match = re.search(r'/\s*(\d+)', text)
                    if match:
                        total = int(match.group(1))
                        print(f"‚úÖ (fallback text) NumƒÉrul total de pagini detectat: {total} din '{text}'")
                        return total
                js_result = self.driver.execute_script("""
                    const walker = document.createTreeWalker(document.body, NodeFilter.SHOW_TEXT);
                    const regex = /\\/\\s*(\\d+)/;
                    while(walker.nextNode()) {
                        const t = walker.currentNode.nodeValue;
                        const m = t.match(regex);
                        if (m) return m[1];
                    }
                    return null;
                """)
                if js_result:
                    total = int(js_result)
                    print(f"‚úÖ (fallback JS) NumƒÉrul total de pagini detectat: {total}")
                    return total
                print(f"‚ö† ({attempt}) Nu am gƒÉsit √ÆncƒÉ numƒÉrul total de pagini, re√Æncerc √Æn {delay_between}s...")
                time.sleep(delay_between)
            except Exception as e:
                print(f"‚ö† ({attempt}) Eroare √Æn get_total_pages: {e}")
                time.sleep(delay_between)
        print("‚ùå Nu s-a reu»ôit extragerea numƒÉrului total de pagini dupƒÉ multiple √ÆncercƒÉri.")
        return 0

    def open_save_popup(self):
        try:
            try:
                self.wait.until(EC.invisibility_of_element_located((By.CSS_SELECTOR, 'div.MuiDialog-container')))
            except Exception:
                self.driver.switch_to.active_element.send_keys(Keys.ESCAPE)
                time.sleep(0.5)
            svg = self.wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'svg[data-testid="SaveAltIcon"]')))
            button = svg
            if svg.tag_name.lower() == "svg":
                try:
                    button = svg.find_element(By.XPATH, "./ancestor::button")
                except Exception:
                    pass
            for attempt in range(1, 4):
                try:
                    button.click()
                    return True
                except ElementClickInterceptedException:
                    print(f"‚ö† click interceptat (√Æncercarea {attempt}), trimit ESC »ôi reiau...")
                    self.driver.switch_to.active_element.send_keys(Keys.ESCAPE)
                    time.sleep(1)
                    continue
            print("‚ùå Nu am reu»ôit sƒÉ dau click pe butonul de deschidere a popup-ului dupƒÉ retry-uri.")
            return False
        except Exception as e:
            print(f"‚ùå Nu am reu»ôit sƒÉ deschid popup-ul de salvare: {e}")
            return False

    def fill_and_save_range(self, start, end):
        try:
            first_input = self.wait.until(EC.presence_of_element_located((By.ID, "first page")))
            print("‚è≥ A»ôtept 2s √Ænainte de a completa primul input...")
            time.sleep(2)
            first_input.send_keys(Keys.CONTROL + "a")
            first_input.send_keys(str(start))
            print(f"‚úèÔ∏è Am introdus primul numƒÉr: {start}")
            print("‚è≥ A»ôtept 2s √Ænainte de a completa al doilea input...")
            time.sleep(2)
            last_input = self.wait.until(EC.presence_of_element_located((By.ID, "last page")))
            last_input.send_keys(Keys.CONTROL + "a")
            last_input.send_keys(str(end))
            print(f"‚úèÔ∏è Am introdus al doilea numƒÉr: {end}")
            print("‚è≥ A»ôtept 2s √Ænainte de a apƒÉsa butonul de salvare...")
            time.sleep(2)
            save_btn = self.wait.until(EC.element_to_be_clickable((
                By.XPATH,
                '//button[.//text()[contains(normalize-space(.), "Salva»õi") or contains(normalize-space(.), "Save")]]'
            )))
            save_btn.click()
            print(f"‚úÖ Segmentul {start}-{end} salvat.")
            return True
        except Exception as e:
            print(f"‚ùå Eroare la completarea/salvarea intervalului {start}-{end}: {e}")
            return False

    def check_daily_limit_reached(self):
        try:
            el = self.driver.find_element(By.XPATH, "//*[contains(text(), 'Daily download limit reached')]")
            if el and el.is_displayed():
                print("‚ö† Limita zilnicƒÉ de download a fost atinsƒÉ (mesaj detectat pe paginƒÉ).")
                return True
        except Exception:
            pass
        return False

    def save_page_range(self, start, end, retries=1):
        for attempt in range(1, retries + 2):
            print(f"üîÑ √éncep segmentul {start}-{end}, √Æncercarea {attempt}")
            if not self.open_save_popup():
                print(f"‚ö† E»ôec la deschiderea popup-ului pentru {start}-{end}")
                time.sleep(1)
                continue
            success = self.fill_and_save_range(start, end)
            if success:
                print("‚è≥ A»ôtept 5s pentru finalizarea descƒÉrcƒÉrii segmentului...")
                time.sleep(5)
                if self.check_daily_limit_reached():
                    return "limit_reached"
                return True
            else:
                print(f"‚ö† Retry pentru segmentul {start}-{end}")
                time.sleep(1)
        print(f"‚ùå Renun»õ la segmentul {start}-{end} dupƒÉ {retries+1} √ÆncercƒÉri.")
        return False

    def save_all_pages_in_batches(self, resume_from=1):
        total = self.get_total_pages()
        if total <= 0:
            print("‚ö† Nu am ob»õinut numƒÉrul total de pagini; nu pot continua.")
            return 0, False  # pagini, limit_reached_flag

        # actualizeazƒÉ total_pages √Æn state √Ænainte de proces
        if self.current_issue_url:
            for item in self.state.setdefault("downloaded_issues", []):
                if item.get("url") == self.current_issue_url:
                    item["total_pages"] = total
                    break
            else:
                self.state["downloaded_issues"].append({
                    "url": self.current_issue_url,
                    "title": "",
                    "subtitle": "",
                    "pages": 0,
                    "completed_at": "",
                    "last_successful_segment_end": 0,
                    "total_pages": total
                })
            self._save_state()

        bs = self.batch_size
        segments = []

        if resume_from == 1:
            first_end = min(bs - 1, total)
            if first_end >= 1:
                segments.append((1, first_end))
            current = bs
        else:
            current = resume_from

        while current <= total:
            end = min(current + bs - 1, total)
            segments.append((current, end))
            current += bs

        for (start, end) in segments:
            print(f"üì¶ Procesez segmentul {start}-{end}")
            result = self.save_page_range(start, end, retries=1)
            if result == "limit_reached":
                self._update_partial_progress(self.current_issue_url, end)
                print("‚ö† Am atins limita zilnicƒÉ √Æn timpul acestui issue; reiau de aici m√¢ine.")
                return end, True
            if not result:
                print(f"‚ùå E»ôec persistent la segmentul {start}-{end}, opresc.")
                return 0, False
            self._update_partial_progress(self.current_issue_url, end)
            time.sleep(1)
        print("üéØ Toate segmentele au fost procesate pentru acest issue.")
        return total, False

    def extract_issue_links_from_collection(self):
        try:
            self.wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'ul.list-group')))
            anchors = self.driver.find_elements(By.CSS_SELECTOR, 'li.list-group-item a[href^="/en/view/"]')
            links = []
            for a in anchors:
                href = a.get_attribute("href")
                if href and '/en/view/' in href:
                    normalized = href.split('?')[0].rstrip('/')
                    links.append(normalized)
            seen = set()
            unique = []
            for l in links:
                if l not in seen:
                    seen.add(l)
                    unique.append(l)
            print(f"üîó Am gƒÉsit {len(unique)} linkuri de issue √Æn colec»õie.")
            return unique
        except Exception as e:
            print(f"‚ùå Eroare la extragerea linkurilor din colec»õie: {e}")
            return []

    def is_issue_fully_done(self, normalized_url):
        for item in self.state.get("downloaded_issues", []):
            if item.get("url") == normalized_url:
                total = item.get("total_pages", 0)
                last = item.get("last_successful_segment_end", 0)
                if total and last >= total:
                    return True
        return False

    def prioritize_links(self, issue_links):
        pending = []
        others = []
        for link in issue_links:
            normalized = link.rstrip('/')
            exists = next((i for i in self.state.get("downloaded_issues", []) if i.get("url") == normalized), None)
            if exists:
                last = exists.get("last_successful_segment_end", 0)
                total = exists.get("total_pages", None)
                if total and last < total:
                    pending.append(link)
                elif not total and last > 0:
                    pending.append(link)
                else:
                    others.append(link)
            else:
                pending.append(link)
        remaining = [l for l in issue_links if l not in pending]
        return pending + remaining

    def open_new_tab_and_download(self, url):
        normalized_url = url.rstrip('/')
        already_done = self.is_issue_fully_done(normalized_url)
        if normalized_url in SKIP_URLS or already_done:
            print(f"‚è≠Ô∏è Sar peste {url} (deja descƒÉrcat).")
            return False

        if self.remaining_quota() <= 0:
            print(f"‚ö† Limita zilnicƒÉ de {DAILY_LIMIT} issue-uri atinsƒÉ. Oprind procesarea.")
            return False

        try:
            print(f"\nüì• Deschid fila pentru {url}")
            if not self.attached_existing:
                self.ensure_alive_fallback()

            def snapshot_folder():
                snaps = {}
                try:
                    for f in os.listdir(self.download_dir):
                        full = os.path.join(self.download_dir, f)
                        if os.path.isfile(full):
                            try:
                                snaps[f] = os.path.getsize(full)
                            except Exception:
                                snaps[f] = None
                except Exception:
                    pass
                return snaps

            before_snap = snapshot_folder()

            prev_handles = set(self.driver.window_handles)
            self.driver.execute_script("window.open('');")
            new_handles = set(self.driver.window_handles)
            diff = new_handles - prev_handles
            if not diff:
                new_handle = self.driver.window_handles[-1]
            else:
                new_handle = diff.pop()
            self.driver.switch_to.window(new_handle)

            if not self.navigate_to_page(url):
                return False

            time.sleep(1)

            title, subtitle = self.get_issue_metadata()

            resume_from = 1
            for item in self.state.get("downloaded_issues", []):
                if item.get("url") == normalized_url and item.get("last_successful_segment_end", 0):
                    resume_from = item.get("last_successful_segment_end", 0) + 1
                    break

            self.current_issue_url = normalized_url

            pages_done, limit_hit = self.save_all_pages_in_batches(resume_from=resume_from)
            if pages_done == 0 and not limit_hit:
                print(f"‚ö† DescƒÉrcarea pentru {url} a e»ôuat complet.")
                return False

            if limit_hit:
                print(f"‚ö† Limita zilnicƒÉ atinsƒÉ √Æn timpul issue-ului {url}; progresul par»õial salvat.")
                return False

            # complet
            self.mark_issue_done(url, pages_done, title=title, subtitle=subtitle, total_pages=pages_done)
            print(f"‚úÖ DescƒÉrcarea pentru {url} finalizatƒÉ complet ({pages_done} pagini).")
            return True

        except WebDriverException as e:
            print(f"‚ùå Eroare WebDriver pentru {url}: {e}")
            return False
        except Exception as e:
            print(f"‚ùå Eroare √Æn open_new_tab_and_download pentru {url}: {e}")
            return False
        finally:
            try:
                self.driver.close()
                if self.driver.window_handles:
                    self.driver.switch_to.window(self.driver.window_handles[0])
            except Exception:
                pass

    def ensure_alive_fallback(self):
        try:
            _ = self.driver.title
        except Exception as e:
            print(f"‚ö† Conexiune WebDriver moartƒÉ ({e}), pornesc instan»õƒÉ nouƒÉ ca fallback.")
            prefs = {
                "download.default_directory": os.path.abspath(self.download_dir),
                "download.prompt_for_download": False,
                "download.directory_upgrade": True,
                "safebrowsing.enabled": True,
            }
            chrome_options = Options()
            chrome_options.add_experimental_option("prefs", prefs)
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument("--disable-gpu")
            chrome_options.add_argument("--window-size=1920,1080")
            chrome_options.add_argument("--incognito")
            self.driver = webdriver.Chrome(options=chrome_options)
            self.wait = WebDriverWait(self.driver, self.timeout)
            self.attached_existing = False

    def run_collection(self, collection_url):
        print(f"üåê √éncep procesarea colec»õiei: {collection_url}")
        if not self.driver:
            print("‚ùå Driver neini»õializat.")
            return False
        if not self.navigate_to_page(collection_url):
            return False
        issue_links = self.extract_issue_links_from_collection()
        if not issue_links:
            print("‚ö† Nu s-au gƒÉsit issue-uri √Æn colec»õie.")
            return False

        ordered = self.prioritize_links(issue_links)

        for link in ordered:
            if self.remaining_quota() <= 0:
                print(f"‚ö† Limita zilnicƒÉ atinsƒÉ ({DAILY_LIMIT}), opresc.")
                break
            self.open_new_tab_and_download(link)
            time.sleep(1)

        all_done = True
        for link in issue_links:
            normalized = link.rstrip('/')
            if not self.is_issue_fully_done(normalized):
                all_done = False
                break
        if all_done:
            print("üéâ Am terminat totul de downloadat")
        else:
            print("‚ö† Mai rƒÉm√¢n issue-uri neterminate, le reiau la urmƒÉtoarea rulare dacƒÉ e altƒÉ zi.")
        return True

    def run(self):
        print("üß™ √éncep executarea Chrome PDF Downloader")
        print("=" * 60)
        try:
            if not self.setup_chrome_driver():
                return False
            if "/collection/" in self.test_url:
                if not self.run_collection(self.test_url):
                    return False
            else:
                if not self.navigate_to_page(self.test_url):
                    return False
                title, subtitle = self.get_issue_metadata()
                resume_from = 1
                exists = next((i for i in self.state.get("downloaded_issues", []) if i.get("url") == self.test_url.rstrip('/')), None)
                if exists and exists.get("last_successful_segment_end", 0):
                    resume_from = exists.get("last_successful_segment_end", 0) + 1
                self.current_issue_url = self.test_url.rstrip('/')
                pages_done, limit_hit = self.save_all_pages_in_batches(resume_from=resume_from)
                if pages_done:
                    if not limit_hit:
                        self.mark_issue_done(self.test_url, pages_done, title=title, subtitle=subtitle, total_pages=pages_done)
                        print(f"üìä Issue unic descƒÉrcat complet: {self.state['count']}/{DAILY_LIMIT}, pagini totale: {self.state['pages_downloaded']}")
                    else:
                        print("‚ö† Issue neterminat din cauza limitei; progresul salvat.")
                else:
                    return False
            print("‚úÖ Toate opera»õiunile au fost ini»õate.")
            return True
        except KeyboardInterrupt:
            print("\n\n‚ö† Interven»õie manualƒÉ: √Æntrerupt.")
            return False
        except Exception as e:
            print(f"\n‚ùå Eroare nea»ôteptatƒÉ: {e}")
            return False
        finally:
            if self.driver:
                if self.attached_existing:
                    print("üîñ Am pƒÉstrat sesiunea Chrome existentƒÉ deschisƒÉ (nu fac quit).")
                else:
                    print("üö™ √énchid browserul.")
                    try:
                        self.driver.quit()
                    except Exception:
                        pass

def main():
    if len(sys.argv) >= 2:
        url = sys.argv[1]
    else:
        url = "https://adt.arcanum.com/en/collection/GazetaMatematica/"
    downloader = ChromePDFDownloader(test_url=url, download_dir="D:\\", batch_size=50)
    success = downloader.run()
    if not success:
        sys.exit(1)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"‚ùå Eroare fatalƒÉ: {e}")
        sys.exit(1)
