#!/usr/bin/env python3
"""
SCRIPT PENTRU CORECÈšIA IMEDIATÄ‚ a issue-ului StudiiSiCercetariMecanicaSiAplicata_1963
RuleazÄƒ acest script pentru a corecta manual problemele identificate.
"""

import json
import os
import shutil
from datetime import datetime

def fix_current_issue():
    """CorecteazÄƒ manual issue-ul problematic"""

    problematic_url = "https://adt.arcanum.com/ro/view/StudiiSiCercetariMecanicaSiAplicata_1963"

    print("ğŸ”§ CORECTEZ MANUAL issue-ul problematic...")
    print(f"ğŸ“ URL: {problematic_url}")
    print("ğŸ“Š Problema: 249/1565 pagini (marcat greÈ™it ca complet)")
    print("=" * 60)

    # PASUL 1: CorecteazÄƒ skip_urls.json
    skip_path = "skip_urls.json"
    if os.path.exists(skip_path):
        print("ğŸ”„ Corectez skip_urls.json...")

        # CreeazÄƒ backup
        backup_skip = f"{skip_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        shutil.copy2(skip_path, backup_skip)
        print(f"ğŸ’¾ Backup creat: {backup_skip}")

        # ÃncarcÄƒ È™i corecteazÄƒ
        with open(skip_path, "r", encoding="utf-8") as f:
            skip_data = json.load(f)

        completed_urls = skip_data.get("completed_urls", [])
        original_count = len(completed_urls)

        # È˜terge URL-ul problematic din toate variantele posibile
        urls_to_remove = [
            problematic_url,
            problematic_url.rstrip('/'),
            problematic_url + '/'
        ]

        for url in urls_to_remove:
            if url in completed_urls:
                completed_urls.remove(url)
                print(f"ğŸ—‘ï¸ È˜TERS din skip_urls: {url}")

        skip_data["completed_urls"] = completed_urls
        skip_data["last_updated"] = datetime.now().isoformat()

        # SalveazÄƒ
        with open(skip_path, "w", encoding="utf-8") as f:
            json.dump(skip_data, f, indent=2, ensure_ascii=False)

        print(f"âœ… skip_urls.json corectat: {original_count} â†’ {len(completed_urls)} URL-uri")
    else:
        print("âš  skip_urls.json nu existÄƒ")

    # PASUL 2: CorecteazÄƒ state.json
    state_path = "state.json"
    if os.path.exists(state_path):
        print("\nğŸ”„ Corectez state.json...")

        # CreeazÄƒ backup
        backup_state = f"{state_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        shutil.copy2(state_path, backup_state)
        print(f"ğŸ’¾ Backup creat: {backup_state}")

        # ÃncarcÄƒ È™i corecteazÄƒ
        with open(state_path, "r", encoding="utf-8") as f:
            state_data = json.load(f)

        issues = state_data.get("downloaded_issues", [])
        found_issues = []
        duplicates_removed = 0

        # GÄƒseÈ™te È™i corecteazÄƒ toate variantele URL-ului
        corrected_issues = []
        for issue in issues:
            url = issue.get("url", "").rstrip('/')

            if url == problematic_url.rstrip('/'):
                found_issues.append(issue)
            else:
                corrected_issues.append(issue)

        if found_issues:
            print(f"ğŸ” GÄƒsite {len(found_issues)} intrÄƒri pentru URL-ul problematic:")

            # GÄƒseÈ™te cea mai bunÄƒ versiune (cu cel mai mult progres)
            best_issue = None
            best_progress = -1

            for issue in found_issues:
                progress = issue.get("last_successful_segment_end", 0)
                print(f"   ğŸ“Š Progres: {progress}, completed_at: {bool(issue.get('completed_at'))}")

                if progress > best_progress:
                    best_progress = progress
                    best_issue = issue

            if len(found_issues) > 1:
                duplicates_removed = len(found_issues) - 1
                print(f"ğŸ—‘ï¸ Elimin {duplicates_removed} dubluri")

            # CorecteazÄƒ cea mai bunÄƒ versiune
            if best_issue:
                print(f"ğŸ”§ Corectez issue-ul cu progresul {best_progress}...")

                best_issue.update({
                    "url": problematic_url,
                    "pages": 0,  # ReseteazÄƒ pentru cÄƒ nu e complet
                    "completed_at": "",  # ReseteazÄƒ
                    "last_successful_segment_end": 249,  # PÄƒstreazÄƒ progresul actual
                    "total_pages": 1565  # CORECTEAZÄ‚ cu valoarea realÄƒ!
                })

                corrected_issues.append(best_issue)
                print("âœ… Issue corectat cu:")
                print(f"   ğŸ“„ total_pages: 1565")
                print(f"   ğŸ”„ last_successful_segment_end: 249")
                print(f"   âŒ completed_at: '' (gol)")
                print(f"   ğŸ“Š Status: PARÈšIAL (va fi continuat)")
        else:
            print("âš  Nu am gÄƒsit issue-ul problematic Ã®n state.json")

        # ActualizeazÄƒ state-ul
        state_data["downloaded_issues"] = corrected_issues

        # RecalculeazÄƒ count-ul corect
        actual_completed = len([i for i in corrected_issues if i.get("completed_at")])
        state_data["count"] = actual_completed

        # SalveazÄƒ
        with open(state_path, "w", encoding="utf-8") as f:
            json.dump(state_data, f, indent=2, ensure_ascii=False)

        print(f"âœ… state.json corectat:")
        print(f"   ğŸ“Š Issues: {len(issues)} â†’ {len(corrected_issues)}")
        print(f"   ğŸ—‘ï¸ Dubluri eliminate: {duplicates_removed}")
        print(f"   âœ… Complet recalculat: {actual_completed}")
    else:
        print("âš  state.json nu existÄƒ")

    print("\n" + "=" * 60)
    print("ğŸ‰ CORECÈšIA COMPLETÄ‚!")
    print("ğŸ¯ Acum poÈ›i rula din nou scriptul - va continua de la pagina 250")
    print("ğŸ“Š Progres aÈ™teptat: 249 â†’ 1565 pagini")
    print("=" * 60)


def verify_correction():
    """VerificÄƒ cÄƒ corecÈ›ia a funcÈ›ionat"""
    problematic_url = "https://adt.arcanum.com/ro/view/StudiiSiCercetariMecanicaSiAplicata_1963"

    print("\nğŸ” VERIFICARE POST-CORECÈšIE:")

    # VerificÄƒ skip_urls.json
    if os.path.exists("skip_urls.json"):
        with open("skip_urls.json", "r", encoding="utf-8") as f:
            skip_data = json.load(f)

        completed_urls = skip_data.get("completed_urls", [])
        is_in_skip = any(url.rstrip('/') == problematic_url.rstrip('/') for url in completed_urls)

        print(f"ğŸ“‹ skip_urls.json: {'âŒ ÃNCÄ‚ ÃN SKIP' if is_in_skip else 'âœ… È˜TERS DIN SKIP'}")

    # VerificÄƒ state.json
    if os.path.exists("state.json"):
        with open("state.json", "r", encoding="utf-8") as f:
            state_data = json.load(f)

        issues = state_data.get("downloaded_issues", [])
        found = None

        for issue in issues:
            if issue.get("url", "").rstrip('/') == problematic_url.rstrip('/'):
                found = issue
                break

        if found:
            total = found.get("total_pages")
            progress = found.get("last_successful_segment_end", 0)
            completed = found.get("completed_at", "")

            print(f"ğŸ“Š state.json gÄƒsit:")
            print(f"   ğŸ“„ total_pages: {total} {'âœ…' if total == 1565 else 'âŒ'}")
            print(f"   ğŸ”„ progres: {progress} {'âœ…' if progress == 249 else 'âŒ'}")
            print(f"   âŒ completed_at: {'GOL âœ…' if not completed else 'SETAT âŒ'}")
        else:
            print("ğŸ“Š state.json: âŒ NU GÄ‚SIT")


if __name__ == "__main__":
    print("ğŸš¨ SCRIPT DE CORECÈšIE URGENTÄ‚")
    print("Corectez issue-ul StudiiSiCercetariMecanicaSiAplicata_1963")
    print()

    fix_current_issue()
    verify_correction()

    print("\nğŸ¯ URMÄ‚TORII PAÈ˜I:")
    print("1. VerificÄƒ cÄƒ corecÈ›ia a funcÈ›ionat (vezi output-ul de mai sus)")
    print("2. RuleazÄƒ din nou scriptul principal Claude-FINAL.py")
    print("3. Scriptul va detecta automat issue-ul parÈ›ial È™i va continua de la pagina 250")
    print("4. Va descÄƒrca paginile 250-1565 pentru a completa issue-ul")